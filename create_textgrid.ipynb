{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textgrids\n",
    "import subprocess\n",
    "import shutil\n",
    "from scipy.io import wavfile\n",
    "from src import asr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define relevant paths and file locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfa_root_dir = 'C:\\\\Users\\\\chris\\\\Documents\\\\MFA'\n",
    "dataset_dir = 'test_dataset'\n",
    "\n",
    "os.makedirs(os.path.join(mfa_root_dir, 'input_files'), exist_ok=True) # Apparently, MFA needs the input files in a specific directory\n",
    "input_dir = os.path.join(mfa_root_dir, 'input_files', dataset_dir)\n",
    "output_dir = os.path.join(mfa_root_dir, 'input_files', dataset_dir, 'results')\n",
    "pronunc_dict_dir = os.path.join(mfa_root_dir, 'pretrained_models', 'dictionary', 'german_mfa.dict')\n",
    "g2p_model_path = os.path.join(mfa_root_dir, 'pretrained_models', 'g2p', 'german_mfa.zip')\n",
    "acoustic_model_path = os.path.join(mfa_root_dir, 'pretrained_models', 'acoustic', 'german_mfa.zip')\n",
    "\n",
    "audio_files = os.listdir(input_dir)\n",
    "audio_file_prefix = [f.split('_')[0] for f in audio_files if f.endswith('.wav')]\n",
    "print(f\"Found {len(audio_file_prefix)} audio files in input directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the textgrid files that will be populated during the alignment process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in audio_file_prefix:\n",
    "    text_file_path = os.path.join(input_dir, f\"{idx}_graphemes.txt\")\n",
    "    audio_file_path = os.path.join(input_dir, f\"{idx}_audio.wav\")\n",
    "\n",
    "    with open(text_file_path, 'r') as f:\n",
    "        graphemes = f.read().strip()\n",
    "        graphemes = asr.normalize_sentence(graphemes)\n",
    "\n",
    "    fs, audio = wavfile.read(audio_file_path)\n",
    "    assert audio.ndim == 1, \"Audio must be mono.\"\n",
    "\n",
    "    # Create a textgrid.\n",
    "    intervals = []\n",
    "    tg = textgrids.TextGrid()\n",
    "    xmax_s = len(audio) / fs\n",
    "    interval = textgrids.Interval(text=graphemes, xmin=0.0, xmax=xmax_s)\n",
    "    intervals.append(interval)\n",
    "    tier = textgrids.Tier(data=intervals, xmin=0.0, xmax=xmax_s)\n",
    "    tg['sentences'] = tier\n",
    "    tg.xmax = xmax_s\n",
    "\n",
    "    # Place the text file in the input directory.\n",
    "    textgrid_file_path = os.path.join(input_dir, f\"{idx}_textgrid.TextGrid\")\n",
    "    tg.write(textgrid_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f\"mfa validate --debug --ignore_acoustics {input_dir} {pronunc_dict_dir}\"\n",
    "print(f\"Running command: {command}\")\n",
    "out = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "print(out.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phonemize missing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_words_file_stump = 'oovs_found_german_mfa' # automatically generated by MFA\n",
    "\n",
    "oov_output_file_path = os.path.join(mfa_root_dir, 'input', f\"{missing_words_file_stump}.txt\")\n",
    "oov_folder_dir = os.path.join(mfa_root_dir, 'oov_corpus')\n",
    "os.makedirs(oov_folder_dir, exist_ok=True)\n",
    "\n",
    "shutil.copy(oov_output_file_path, oov_folder_dir)\n",
    "command = f\"mfa g2p --clean {oov_folder_dir} german_mfa {os.path.join(mfa_root_dir, missing_words_file_stump, missing_words_file_stump)}_g2p.txt\"\n",
    "out = subprocess.run(command, shell=True, capture_output=True, text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the missing words to the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f\"mfa model add_words german_mfa {os.path.join(mfa_root_dir, missing_words_file_stump, missing_words_file_stump)}_g2p.txt\"\n",
    "subprocess.run(command, shell=True, capture_output=True, text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "command = f\"mfa align --clean --debug --overwrite {input_dir} {pronunc_dict_dir} {acoustic_model_path} {output_dir}\"\n",
    "out = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "# TODO: FIX ERROR. REINSTALL ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mfa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
