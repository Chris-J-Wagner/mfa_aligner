{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import textgrids\n",
    "import subprocess\n",
    "import shutil\n",
    "from scipy.io import wavfile\n",
    "from src import asr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define relevant paths and file locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output directories.\n",
    "mfa_root_dir = \"TODO_ADD\" # Usually in Users/Documents/MFA or something similar.\n",
    "input_dir = os.path.join(\"input_files\", \"test_dataset\", \"input\")\n",
    "output_dir = os.path.join(\"input_files\", \"test_dataset\", \"results\")\n",
    "\n",
    "### These path's should exist relative to the MFA root directory.\n",
    "pronunc_dict_dir = os.path.join(mfa_root_dir, 'pretrained_models', 'dictionary', 'german_mfa.dict')\n",
    "g2p_model_path = os.path.join(mfa_root_dir, 'pretrained_models', 'g2p', 'german_mfa.zip')\n",
    "acoustic_model_path = os.path.join(mfa_root_dir, 'pretrained_models', 'acoustic', 'german_mfa.zip')\n",
    "\n",
    "# Find all audio files in input directory.\n",
    "files = os.listdir(input_dir)\n",
    "audio_files = [f for f in files if f.endswith('.wav')]\n",
    "text_files = [f for f in files if f.endswith('.txt')]\n",
    "assert len(audio_files) == len(text_files)\n",
    "audio_files = sorted(audio_files, key=lambda x: int(x.split('_')[0]))\n",
    "text_files = sorted(text_files, key=lambda x: int(x.split('_')[0]))\n",
    "# Add full path to files.\n",
    "audio_files = [os.path.join(input_dir, f) for f in audio_files]\n",
    "text_files = [os.path.join(input_dir, f) for f in text_files]\n",
    "print(f\"Found {len(audio_files)} audio files and {len(text_files)} text files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the textgrid files that will be populated during the alignment process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, files in enumerate(zip(audio_files, text_files)):\n",
    "\n",
    "    audio_file_path, text_file_path = files\n",
    "    assert audio_file_path.split('_')[0] == text_file_path.split('_')[0]\n",
    "    \n",
    "    with open(text_file_path, 'r') as f:\n",
    "        graphemes = f.read().strip()\n",
    "        graphemes = asr.normalize_sentence(graphemes)\n",
    "\n",
    "    fs, audio = wavfile.read(audio_file_path)\n",
    "    assert audio.ndim == 1, \"Audio must be mono.\"\n",
    "\n",
    "    # Create a textgrid.\n",
    "    intervals = []\n",
    "    tg = textgrids.TextGrid()\n",
    "    xmax_s = len(audio) / fs\n",
    "    interval = textgrids.Interval(text=graphemes, xmin=0.0, xmax=xmax_s)\n",
    "    intervals.append(interval)\n",
    "    tier = textgrids.Tier(data=intervals, xmin=0.0, xmax=xmax_s)\n",
    "    tg['sentences'] = tier\n",
    "    tg.xmax = xmax_s\n",
    "\n",
    "    # Place the text file in the input directory.\n",
    "    textgrid_file_path = os.path.join(input_dir, f\"{idx}_textgrid.TextGrid\")\n",
    "    tg.write(textgrid_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f\"mfa validate --debug --ignore_acoustics {input_dir} {pronunc_dict_dir}\"\n",
    "print(f\"Running command: {command}\")\n",
    "out = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "print(out.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phonemize missing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_words_file_stump = 'oovs_found_german_mfa' # automatically generated by MFA\n",
    "\n",
    "oov_output_file_path = os.path.join(mfa_root_dir, 'input', f\"{missing_words_file_stump}.txt\")\n",
    "oov_folder_dir = os.path.join(mfa_root_dir, 'oov_corpus')\n",
    "os.makedirs(oov_folder_dir, exist_ok=True)\n",
    "\n",
    "shutil.copy(oov_output_file_path, oov_folder_dir)\n",
    "command = f\"mfa g2p --clean {oov_folder_dir} german_mfa {os.path.join(mfa_root_dir, missing_words_file_stump, missing_words_file_stump)}_g2p.txt\"\n",
    "out = subprocess.run(command, shell=True, capture_output=True, text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the missing words to the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f\"mfa model add_words german_mfa {os.path.join(mfa_root_dir, missing_words_file_stump, missing_words_file_stump)}_g2p.txt\"\n",
    "subprocess.run(command, shell=True, capture_output=True, text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "command = f\"mfa align --clean --debug --overwrite {input_dir} {pronunc_dict_dir} {acoustic_model_path} {output_dir}\"\n",
    "out = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "print(out.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mfa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
